# =============================================================================
# OCR Provenance MCP System - Environment Configuration
# =============================================================================
# Fill in your API keys and adjust settings as needed

# -----------------------------------------------------------------------------
# DATALAB API CONFIGURATION
# -----------------------------------------------------------------------------
# Required: Get your API key from https://www.datalab.to
DATALAB_API_KEY=your_api_key_here

# Datalab API base URL
DATALAB_BASE_URL=https://www.datalab.to/api/v1

# OCR processing mode: fast | balanced | accurate
DATALAB_DEFAULT_MODE=accurate

# Maximum concurrent API requests
DATALAB_MAX_CONCURRENT=3

# Request timeout in milliseconds (5 minutes)
DATALAB_TIMEOUT=300000

# -----------------------------------------------------------------------------
# EMBEDDING MODEL CONFIGURATION
# -----------------------------------------------------------------------------
# Local embedding model for vector search (local path or HuggingFace model ID)
EMBEDDING_MODEL=./models/nomic-embed-text-v1.5

# Embedding vector dimensions
EMBEDDING_DIMENSIONS=768

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=512

# Force GPU loading (never use CPU for embeddings)
EMBEDDING_DEVICE=cuda
EMBEDDING_USE_GPU=true
EMBEDDING_TRUST_REMOTE_CODE=true

# -----------------------------------------------------------------------------
# GPU CONFIGURATION (NVIDIA RTX 5090 / CUDA)
# -----------------------------------------------------------------------------
# GPU device identifier
GPU_DEVICE=cuda:0

# Data type for GPU inference: float16 | float32 | bfloat16
GPU_DTYPE=float16

# Enable torch.compile for model optimization
GPU_COMPILE_MODEL=true

# Maximum GPU memory fraction to use (0.0 - 1.0)
GPU_MEMORY_FRACTION=0.9

# -----------------------------------------------------------------------------
# CUDA / PYTORCH ENVIRONMENT
# -----------------------------------------------------------------------------
# Force CUDA device visibility
CUDA_VISIBLE_DEVICES=0

# PyTorch CUDA settings
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# Disable CPU fallback - fail if GPU unavailable
FORCE_GPU=true
NO_CPU_FALLBACK=true

# -----------------------------------------------------------------------------
# TEXT CHUNKING CONFIGURATION
# -----------------------------------------------------------------------------
# Maximum characters per chunk
CHUNKING_SIZE=2000

# Overlap percentage between chunks (0-50)
CHUNKING_OVERLAP_PERCENT=10

# -----------------------------------------------------------------------------
# STORAGE CONFIGURATION
# -----------------------------------------------------------------------------
# Path to store SQLite databases with vector extensions
STORAGE_DATABASES_PATH=~/.ocr-provenance/databases/

# Current active database name (optional)
STORAGE_CURRENT_DATABASE=

# -----------------------------------------------------------------------------
# PROVENANCE TRACKING CONFIGURATION
# -----------------------------------------------------------------------------
# Hash algorithm for document integrity: sha256 | sha512 | blake2b
PROVENANCE_HASH_ALGORITHM=sha256

# Export format for provenance data: json | xml
PROVENANCE_EXPORT_FORMAT=json

# -----------------------------------------------------------------------------
# MCP SERVER CONFIGURATION
# -----------------------------------------------------------------------------
# Server name for MCP protocol
MCP_SERVER_NAME=ocr-provenance

# Server version
MCP_SERVER_VERSION=1.0.0

# Enable debug logging
MCP_DEBUG=false

# Log level: debug | info | warn | error
LOG_LEVEL=info
